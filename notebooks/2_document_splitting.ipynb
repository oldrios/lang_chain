{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Document Splitting` in Lang Chain involves the process of breaking down lengthy texts into smaller, manageable chunks suitable for processing by language models. The goal is to ensure that these chunks are semantically coherent, meaning that related pieces of text stay together, which can vary depending on the text type. Lang Chain offers a range of built-in text splitters within the langchain-text-splitters package, each with different methods of splitting text (e.g., by sentences, HTML or Markdown characters, specific code language characters, tokens, or even semantic similarity) and measuring chunk size. Some splitters also add metadata to each chunk, providing context about its origin. This functionality is crucial for handling large documents efficiently, enabling users to customize the splitting process based on their specific needs, and making it easier to integrate with language models for further processing or analysis. Additionally, tools like Chunkviz aid in evaluating and visualizing the effectiveness of text splitters, facilitating the optimization of text splitting strategies.\n",
    "\n",
    "More of text splitting in [LangChain Official Documentation](https://python.langchain.com/docs/modules/data_connection/document_transformers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"document_splitting.png\" /></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why doesn't this split the string below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: NOSSA QUE LEGAL ISSO AQUI - Tamanho: 25\n",
      "split: ESTOU TENTANDO MAIS EXEMPLOS PRA ENTENDER SE FAZ SENTIDO USAR ESSE SPLITTER - Tamanho: 75\n"
     ]
    }
   ],
   "source": [
    "text4 = 'NOSSA QUE LEGAL ISSO AQUI. ESTOU TENTANDO MAIS EXEMPLOS PRA ENTENDER SE FAZ SENTIDO USAR ESSE SPLITTER'\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = '.'\n",
    ")\n",
    "\n",
    "for x in c_splitter.split_text(text4):\n",
    "    print(\"split:\",  x, \"- Tamanho:\",len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: NOSSA QUE LEGAL ISSO AQUI. - Tamanho: 26\n",
      "split: ESTOU TENTANDO MAIS - Tamanho: 19\n",
      "split: EXEMPLOS PRA ENTENDER SE - Tamanho: 24\n",
      "split: SE FAZ SENTIDO USAR ESSE - Tamanho: 24\n",
      "split: SPLITTER - Tamanho: 8\n"
     ]
    }
   ],
   "source": [
    "for x in r_splitter.split_text(text4):\n",
    "    print(\"split:\",  x, \"- Tamanho:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\", \".\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \n",
      "\n",
      " Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, - Tamanho: 448\n",
      "split: have a space.and words are separated by space. - Tamanho: 46\n"
     ]
    }
   ],
   "source": [
    "for x in c_splitter.split_text(some_text):\n",
    "    print(\"split:\",  x, \"- Tamanho:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c_splitter`: there is no sense the two chunks made by splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. - Tamanho: 248\n",
      "split: Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space. - Tamanho: 243\n"
     ]
    }
   ],
   "source": [
    "for x in r_splitter.split_text(some_text):\n",
    "    print(\"split:\",  x, \"- Tamanho:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r_splitter`: there is more sense the two chunks made by splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document - Tamanho: 247\n",
      "split: Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space - Tamanho: 242\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=0,\n",
    "    separator = '.'\n",
    ")\n",
    "\n",
    "for x in c_splitter.split_text(some_text):\n",
    "    print(\"split:\",  x, \"- Tamanho:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are using an approach more effective for `c_splitter` than before. All splitter strategy depends only shape / format of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PDF Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning is th e most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about  teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thin g in computer science, but \n",
      "the most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learni ng and all aspects of machin e learning. Paul Baumstarck\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': '../docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '../docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n\n",
    "### Section A\\n\\n\n",
    "Hi this is Lance\\n\\n\n",
    "### Section B\\n\\n\n",
    "Hi this is Paul\\n\\n\n",
    "## Chapter 2\\n\\n\n",
    "Hi this is Mike\\n\\n\n",
    "### Section C\\n\\n\n",
    "Hi this is Joe\\n\\n\n",
    "### Section D\\n\\n\n",
    "Hi this is Paul\\n\\n\n",
    "## Chapter 3\\n\\n\n",
    "Hi this is Mike\\n\\n\n",
    "### Section E\\n\\n\n",
    "Hi this is Joe\\n\\n\n",
    "### Section F\\n\\n\n",
    "Hi this is Paul\\n\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    ('#', 'Header 1'),\n",
    "    ('##', 'Header 2'),\n",
    "    ('###', 'Header 3'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section A'})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on a real Markdown file, like a md file in repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"./\", glob=\"*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    ('#', 'Header 1'),\n",
    "    ('##', 'Header 2'),\n",
    "    ('###', 'Header 3'),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"This document chronicles my journey through a challenge encountered in a Langchain course offered by DeepLearning.AI. The course recommended using OpenAI's API for audio transcription, a resource I neither had access to nor could use locally on my machine. Faced with this limitation, I embarked on a quest to find a workaround that allowed me to perform the transcription locally, utilizing my NVIDIA GeForce GTX 1650 GPU. This narrative covers the problem, the solution I devised, and the invaluable lessons learned along the way.\", metadata={'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'Introduction'})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits = markdown_splitter.split_text(txt)\n",
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'Introduction'}\n",
      "This document chronicles my journey through a challenge encountered in a Langchain course offered by DeepLearning.AI. The course recommended using OpenAI's API for audio transcription, a resource I neither had access to nor could use locally on my machine. Faced with this limitation, I embarked on a quest to find a workaround that allowed me to perform the transcription locally, utilizing my NVIDIA GeForce GTX 1650 GPU. This narrative covers the problem, the solution I devised, and the invaluable lessons learned along the way.\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'The Problem'}\n",
      "In the context of the course, the OpenAIWhisperParser API was utilized for transcribing audio from YouTube videos. However, this API is part of OpenAI's paid services, which was not a feasible option for me. Additionally, the necessity for a local solution was paramount, as my objective was to utilize my GPU to its fullest potential, thereby accelerating the transcription process.\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'The Solution', 'Header 3': 'Step 1: Preparing the Local Environment'}\n",
      "#### Setting up CUDA and cuDNN  \n",
      "To harness the power of my NVIDIA GeForce GTX 1650 GPU, setting up the CUDA environment was imperative. This involved:  \n",
      "1. **Installing the NVIDIA Driver**: Ensuring compatibility with the GTX 1650.\n",
      "2. **Downloading and Installing the CUDA Toolkit**: Selecting a version compatible with the PyTorch installation.\n",
      "3. **Installing cuDNN**: Integrating it with the CUDA setup to optimize deep learning tasks.\n",
      "4. **Verifying the Installation**: Confirming that CUDA was recognized and operational on my system.  \n",
      "#### Installing PyTorch with CUDA Support  \n",
      "With the environment ready, the next step was to install PyTorch configured for CUDA:  \n",
      "```shell\n",
      "pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
      "```  \n",
      "Validating CUDA Integration with PyTorch\n",
      "Ensuring PyTorch's ability to leverage GPU acceleration:  \n",
      "```python\n",
      "import torch\n",
      "print(torch.cuda.is_available())  # Expected output: True\n",
      "```\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'The Solution', 'Header 3': 'Step 2: Local Audio Transcription'}\n",
      "With the API out of reach, the focus shifted to local solutions. This involved downloading the YouTube video's audio and utilizing the Whisper model for transcription:  \n",
      "1. **Downloading the Video's Audio**: Utilizing yt_dlp and pydub for audio extraction.  \n",
      "```python\n",
      "! pip install yt_dlp\n",
      "! pip install pydub\n",
      "! pip install langchain\n",
      "from langchain.document_loaders.generic import GenericLoader\n",
      "from langchain.document_loaders.parsers.audio import OpenAIWhisperParserLocal\n",
      "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
      "\n",
      "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
      "save_dir=\"../../docs/youtube/\"\n",
      "\n",
      "YoutubeAudioLoader([url],save_dir)\n",
      "\n",
      "loader = GenericLoader(\n",
      "YoutubeAudioLoader([url],save_dir),\n",
      "OpenAIWhisperParser()\n",
      ")\n",
      "docs = loader.load()\n",
      "```\n",
      "`Note`: This code will return an error because it's necessary an Openai API key valid. This step is only to download and exctrat the audio from the Youtube video.  \n",
      "2. **Performing Local Transcription with Whisper**: Transcribing the audio file and saving the results in a JSON format for further processing.  \n",
      "```python\n",
      "! pip install -U openai-whisper\n",
      "import json\n",
      "import whisper\n",
      "\n",
      "model = whisper.load_model(\"base\", device=\"cuda\")\n",
      "audio_path = \"../../docs/youtube/Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a\"\n",
      "result = model.transcribe(audio_path, language = \"en\", fp16=False)\n",
      "\n",
      "# Path to save transcript\n",
      "path_youtube_transcript = \"../../docs/youtube/transcript.json\"\n",
      "\n",
      "# Serializa transcript to JSON\n",
      "with open(path_youtube_transcript, 'w', encoding='utf-8') as arquivo:\n",
      "json.dump(result, arquivo, ensure_ascii=False, indent=4)\n",
      "```  \n",
      "3. **Using transcript JSON to make Langchain Document**: Now it's possible to transform one Youtube video into a Langchain document.  \n",
      "```python\n",
      "!pip install jq\n",
      "\n",
      "from langchain_community.document_loaders import JSONLoader\n",
      "\n",
      "loader = JSONLoader(\n",
      "file_path=path_youtube_transcript,\n",
      "jq_schema='.segments[].text',\n",
      "text_content=False)\n",
      "\n",
      "data = loader.load()\n",
      "```\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'The Solution', 'Header 3': 'Step 3: A Simplified Alternative'}\n",
      "After navigating through the complex setup and local transcription process, a simpler alternative emerged. The YouTube transcripts doc loader offered an efficient and easier path to the same goal:  \n",
      "```python\n",
      "! pip install --upgrade --quiet youtube-transcript-api\n",
      "! pip install --upgrade --quiet pytube\n",
      "from langchain_community.document_loaders import YoutubeLoader\n",
      "\n",
      "loader = YoutubeLoader.from_youtube_url(\n",
      "\"https://www.youtube.com/watch?v=jGwO_UgTS7I\",\n",
      "add_video_info=True,\n",
      "language=[\"en\", \"id\"],\n",
      "translation=\"en\",\n",
      ")\n",
      "docs = loader.load()\n",
      "```\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'Lessons Learned'}\n",
      "- **Thorough Documentation Review**: Before delving into complex solutions, exploring official documentation and simpler alternatives can save time and effort.\n",
      "- **Leveraging Local GPU for Efficiency**: The experience underscored the value of setting up and utilizing local GPU resources for tasks requiring significant computational power, such as audio transcription.\n",
      "--------------------------------------------------\n",
      "{'Header 1': 'Overcoming OpenAI API Limitations with Local GPU Acceleration for Audio Transcription', 'Header 2': 'Conclusion'}\n",
      "This journey from facing a restrictive limitation to discovering an efficient, local solution has been both challenging and enlightening. Not only did it enhance my understanding of CUDA setup and local GPU utilization, but it also highlighted the importance of seeking simpler solutions and the vast potential of open-source tools in overcoming obstacles.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for document in md_header_splits:\n",
    "    print(document.metadata)\n",
    "    print(document.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
